{
    "batch_size_per_gpu": 16,
    "max_batch_size_per_gpu": 20,
    "gradient_accumulation_steps": 4,
    "global_batch_size": 64,
    "dp_size": 1,
    "tp_size": 1,
    "pp_size": 4,
    "sp_size": 1,
    "ep_size": 1,
    "ds_zero": "NONE",
    "total_num_gpus": 4,
    "seq_len": 1400,
    "total_num_tokens": 1280,
    "num_params_total": 3297449600.0,
    "num_active_params_total": 3297449600.0,
    "activation_recomputation": "FULL",
    "layernorm_dtype_bytes": 4,
    "mlp_activation_quant_bits": null,
    "mlp_recompute_gelu": true,
    "achieved_flops": 115.63999999999999,
    "flops_efficiency": 0.35,
    "hbm_memory_efficiency": 0.5,
    "num_flops_total_per_micro_batch": 632619008000000.0,
    "weight_memory_per_gpu": 1925216000.0,
    "weight_memory_embedding_per_gpu": 204800000.0,
    "weight_memory_attn_per_gpu": 573440000.0,
    "weight_memory_mlp_per_gpu": 1146880000.0,
    "weight_memory_layernorm_per_gpu": 89600.0,
    "gradient_memory_per_gpu": 3850432000.0,
    "optimizer_state_memory_per_gpu": 11551296000.0,
    "(weight+op_state+grad)_memory_per_gpu": 17326944000.0,
    "activation_memory_batch_size_1": 412160000.0,
    "activation_memory_per_gpu": 6594560000.0,
    "activation_memory_attn_per_gpu": 0,
    "activation_memory_mlp_per_gpu": 0,
    "activation_memory_layernorm_per_gpu": 0,
    "activation_memory_embedding_output_per_gpu": 2867200000.0,
    "(weight+op_state+grad+act)_memory_per_gpu": 23921504000.0,
    "memory_left_per_gpu": 1848299776.0,
    "memory_used_per_gpu": 23921504000.0,
    "latency_per_micro_batch": 1.367647457627119,
    "latency_fwd": 0.35335989238633303,
    "latency_fwd_attn": 0.11603680387409201,
    "latency_fwd_mlp": 0.19041937046004842,
    "latency_fwd_layernorm": 0.006826666666666667,
    "latency_fwd_tp_comm": 0,
    "latency_fwd_input_embedding": 0.00040634920634920635,
    "latency_fwd_output_embedding_loss": 0.03967070217917676,
    "latency_per_iter": 5.470589830508476,
    "total_training_latency": 0.0,
    "gpu_hours": 0.0
}